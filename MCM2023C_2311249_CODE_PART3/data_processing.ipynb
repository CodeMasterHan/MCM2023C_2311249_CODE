{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "reports_num = pd.read_excel('Problem_C_Data_Wordle_edited.xlsx')\n",
    "words_attributes = pd.read_excel('features_final.xlsx')\n",
    "words = pd.read_table('Words.txt')\n",
    "fres = pd.read_table('COCA词频表.txt',encoding = 'gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-d23e17e3079f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# letter frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Words.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mletters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'abcdefghijklmnopqrstuvwxyz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;31m# default to avoid a ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Words.txt'"
     ]
    }
   ],
   "source": [
    "# letter frequency\n",
    "letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "frequency = {}\n",
    "for i in range(26):\n",
    "    for j in range(12972):\n",
    "        if letters[i] in words.loc[j][0]:\n",
    "            if letters[i] in frequency:\n",
    "                frequency[letters[i]] += words.loc[j][0].count(letters[i])\n",
    "            else:\n",
    "                frequency[letters[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lance\n",
      "clean\n",
      "uncle\n",
      "clone\n",
      "ancle\n",
      "cline\n",
      "incel\n",
      "incle\n",
      "hasty\n",
      "trash\n",
      "shaft\n",
      "shalt\n",
      "swath\n",
      "haste\n",
      "stash\n",
      "ashet\n",
      "bahts\n",
      "baths\n",
      "bhats\n",
      "chats\n",
      "gaths\n",
      "ghast\n",
      "ghats\n",
      "hadst\n",
      "haets\n",
      "hafts\n",
      "halts\n",
      "hants\n",
      "harts\n",
      "hasta\n",
      "hates\n",
      "heast\n",
      "heats\n",
      "hoast\n",
      "hosta\n",
      "khats\n",
      "laths\n",
      "maths\n",
      "oaths\n",
      "paths\n",
      "raths\n",
      "saith\n",
      "scath\n",
      "shakt\n",
      "shoat\n",
      "snath\n",
      "staph\n",
      "tachs\n",
      "tahas\n",
      "tahrs\n",
      "taish\n",
      "tanhs\n",
      "taths\n",
      "thans\n",
      "thars\n",
      "thaws\n",
      "whats\n"
     ]
    }
   ],
   "source": [
    "# match the wrong word\n",
    "for i in range(12972):\n",
    "    if 'c' in words.loc[i][0] and 'l' in words.loc[i][0] and 'e' in words.loc[i][0] and 'n' in words.loc[i][0]:\n",
    "        print(words.loc[i][0])\n",
    "for i in range(12972):\n",
    "    if 't' in words.loc[i][0] and 'a' in words.loc[i][0] and 's' in words.loc[i][0] and 'h' in words.loc[i][0]:\n",
    "        print(words.loc[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4859.0\n",
      "0.7246221950847199\n"
     ]
    }
   ],
   "source": [
    "# letter frequency of eerie\n",
    "frequency_eerie = 0\n",
    "for i in range(26):\n",
    "    for j in range(12972):\n",
    "        if letters[i] in 'eerie':\n",
    "            frequency_eerie += words.loc[j][0].count(letters[i])\n",
    "print(frequency_eerie/3)\n",
    "min_fre = min(frequency.values())\n",
    "max_fre = max(frequency.values())\n",
    "fre_errie = (frequency_eerie/3-min_fre)/(max_fre-min_fre)\n",
    "print(fre_errie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "[105, 29, 142, 126, 32]\n",
      "{'a': [737, 2263, 1236, 1073, 680], 'b': [909, 81, 335, 243, 59], 'c': [921, 176, 392, 411, 127], 'd': [685, 84, 390, 471, 823], 'e': [303, 1628, 882, 2327, 1522], 'f': [598, 24, 178, 233, 82], 'g': [638, 76, 363, 423, 143], 'h': [489, 546, 120, 235, 370], 'i': [165, 1382, 1051, 880, 280], 'j': [202, 11, 46, 29, 3], 'k': [376, 95, 272, 503, 259], 'l': [577, 699, 848, 771, 476], 'm': [693, 188, 511, 402, 182], 'n': [325, 345, 964, 788, 530], 'o': [262, 2096, 993, 698, 389], 'p': [859, 231, 364, 418, 147], 'q': [78, 15, 13, 2, 4], 'r': [628, 940, 1198, 719, 672], 's': [1565, 93, 533, 516, 3958], 't': [815, 239, 616, 898, 727], 'u': [189, 1187, 667, 401, 67], 'v': [242, 52, 240, 156, 4], 'w': [413, 163, 271, 128, 64], 'x': [16, 57, 133, 12, 70], 'y': [181, 271, 213, 108, 1301], 'z': [105, 29, 142, 126, 32]}\n"
     ]
    }
   ],
   "source": [
    "# letter location\n",
    "locations = {}\n",
    "for i in range(26):\n",
    "    count = [0,0,0,0,0]\n",
    "    for j in range(12972):\n",
    "        for k in range(5):\n",
    "            try :\n",
    "                if letters[i] == words.loc[j][0][k]:\n",
    "                    count[k] +=1\n",
    "            except IndexError:\n",
    "                continue\n",
    "    locations[letters[i]] = count\n",
    "\n",
    "for lo in locations.values():\n",
    "    su = sum(lo)\n",
    "    for i in range(5):\n",
    "        lo[i] = lo[i]/su\n",
    "        \n",
    "print(locations)\n",
    "df = pd.DataFrame(list(locations.items()),columns=['1','2'])\n",
    "df.to_excel('word_location.xlsx','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter location for word\n",
    "def wordLocation(word):\n",
    "    location_sum = 0\n",
    "    for i in range(5):\n",
    "        location_sum += locations[word[i]][i]\n",
    "    location_aver = location_sum/5\n",
    "    return location_aver\n",
    "\n",
    "word_locations = {}\n",
    "for word in repo_words:\n",
    "    if word == 'naïve':\n",
    "        word = 'naive'\n",
    "    try:\n",
    "        word_locations[word] = wordLocation(word)\n",
    "    except IndexError:\n",
    "        continue\n",
    "        \n",
    "df = pd.DataFrame(list(word_locations.items()),columns=['1','2'])\n",
    "df.to_excel('word_locations.xlsx','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word frequency\n",
    "fresdic = {}\n",
    "count = 0\n",
    "for i in range(20199):\n",
    "    if type(fres.loc[i][0])==float:\n",
    "        pass\n",
    "    elif len(fres.loc[i][0])==5:\n",
    "        fresdic[fres.loc[i][0]] = i\n",
    "        count +=1\n",
    "\n",
    "repo_words = reports_num.loc[:,'Word']\n",
    "words_fre = {}\n",
    "\n",
    "count = 0\n",
    "for word in repo_words:\n",
    "    if word in fresdic.keys():\n",
    "        words_fre[word] = fresdic[word]\n",
    "        count+=1\n",
    "    else:\n",
    "        words_fre[word] = 'out of range'\n",
    "\n",
    "df = pd.DataFrame(list(words_fre.items()),columns=['1','2'])\n",
    "df.to_excel('word_frequency.xlsx','w')\n",
    "\n",
    "for i in range(359):\n",
    "    if len(repo_words[i])!=5:\n",
    "        print(359-i)\n",
    "        print(repo_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8361\n",
      "9254\n",
      "15183\n",
      "20193\n",
      "34\n",
      "0.4130661243117218\n"
     ]
    }
   ],
   "source": [
    "# word frequency for eerie、trash and stash\n",
    "if 'eerie' in fresdic.keys():\n",
    "    print(fresdic['eerie'])\n",
    "\n",
    "if 'trash' in fresdic.keys():\n",
    "    print(fresdic['trash'])\n",
    "\n",
    "if 'stash' in fresdic.keys():\n",
    "    print(fresdic['stash'])\n",
    "min_fre = min(fresdic.values())\n",
    "max_fre = max(fresdic.values())\n",
    "fre_errie = (fresdic['eerie']-min_fre)/(max_fre-min_fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
